{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6bc6cc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de2b24",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concat_data_from_csv(data: list) -> pd.DataFrame:\n",
    "    \"\"\"Load multiple CSV files, remove unnecessary rows, and concatenate them into a single DataFrame.\n",
    "\n",
    "    This function reads multiple CSV files into pandas DataFrames, removes rows where\n",
    "    the column \"resource\" has the value \"lon\", and then concatenates all the DataFrames\n",
    "    into a single one.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of file paths (str) pointing to CSV files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A concatenated DataFrame containing the cleaned data from all input files.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If any of the specified CSV files cannot be found.\n",
    "        pd.errors.EmptyDataError: If a CSV file is empty.\n",
    "        KeyError: If the column \"resource\" is not present in one of the CSV files.\"\"\"\n",
    "    dataframes = []\n",
    "    for file in data:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        ## Esses dados \"lon\" são inuteis e não deveriam estar no dataset\n",
    "        df = df[df[\"resource\"] != \"lon\"]\n",
    "\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itu_415_csv_locations = [\"../../data/full_history_ITU-415_2025-06-01_a_2025-06-17.csv\", \"../../data/full_history_ITU-415_2025-06-17_a_2025-06-29.csv\",\n",
    "                            \"../../data/full_history_ITU-415_2025-06-29_a_2025-06-31.csv\", \"../../data/full_history_ITU-415_2025-07-01_a_2025-07-17.csv\"]\n",
    "\n",
    "df_itu_693_csv_locations = [\"../../data/full_history_ITU-693_2025-05-01_a_2025-06-08.csv\", \"../../data/full_history_ITU-693_2025-06-08_a_2025-07-22.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ffdde",
   "metadata": {},
   "source": [
    "## Funções ajustadas para Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9282bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustTimestampColumn(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that converts the 'timestamp' column to datetime format.\n",
    "\n",
    "    This transformer is compatible with scikit-learn pipelines. It ensures that the\n",
    "    'timestamp' column in the input DataFrame is converted to a pandas datetime object\n",
    "    using the ISO8601 format.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Does nothing and returns self. Required for compatibility with\n",
    "            scikit-learn pipelines.\n",
    "        transform(X):\n",
    "            Returns a copy of the DataFrame with the 'timestamp' column converted\n",
    "            to datetime.\"\"\"\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"ISO8601\")\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveDuplicatesAndNaN(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that fills missing values and removes duplicate rows.\n",
    "\n",
    "    This transformer is designed to be used within scikit-learn pipelines.\n",
    "    It fills missing values in each column with the column's mode (most frequent value)\n",
    "    and then removes any duplicate rows from the DataFrame.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Returns self. Included for compatibility with scikit-learn pipelines.\n",
    "        transform(X):\n",
    "            Returns a cleaned DataFrame with missing values filled and duplicates removed.\"\"\"\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        df_filled = df.apply(lambda col: col.fillna(col.mode().iloc[0]) if col.isnull().any() else col)\n",
    "        df_cleaned = df_filled.drop_duplicates()\n",
    "        return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc95f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreatHighValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that caps high values and creates a running status flag.\n",
    "\n",
    "    This transformer is intended for use in scikit-learn pipelines. It checks the\n",
    "    column value in the input DataFrame and applies the following rules:\n",
    "    \n",
    "    - If value exceeds max_limit, it is replaced with 0.\n",
    "    - A new column running is created, set to 1 when value is within the limit\n",
    "      and 0 otherwise.\n",
    "\n",
    "    Args:\n",
    "        max_limit (int, optional): Maximum allowed value for the value column.\n",
    "            Values above this threshold are set to 0. Defaults to 20000.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Returns self. Required for scikit-learn pipeline compatibility.\n",
    "        transform(X):\n",
    "            Returns a DataFrame with capped values and a new running column.\"\"\"\n",
    "    def __init__(self, max_limit: int = 20000):\n",
    "        self.max_limit = max_limit\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        df['running'] = np.where(df['value'] > self.max_limit, 0, 1)\n",
    "        df['value'] = np.where(df['value'] > self.max_limit, 0, df['value'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbe80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixBatteryAndAlternatorValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that adjusts battery and alternator voltage values.\n",
    "\n",
    "    This transformer is compatible with scikit-learn pipelines. It modifies the\n",
    "    `value` column for specific resources:\n",
    "    \n",
    "    - For rows where `resource` is `\"Bat_V\"`, the `value` is divided by 10.\n",
    "    - For rows where `resource` is `\"Char_V\"`, the `value` is divided by 10.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Returns self. Included for compatibility with scikit-learn pipelines.\n",
    "        transform(X):\n",
    "            Returns a DataFrame with adjusted values for `\"Bat_V\"` and `\"Char_V\"`.\"\"\"\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        df.loc[df[\"resource\"] == \"Bat_V\", \"value\"] = df.loc[df[\"resource\"] == \"Bat_V\", \"value\"] / 10\n",
    "        df.loc[df[\"resource\"] == \"Char_V\", \"value\"] = df.loc[df[\"resource\"] == \"Char_V\", \"value\"] / 10\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PivotDataframe(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that pivots, resamples, and cleans time-series data for each motor pump.\n",
    "\n",
    "    This transformer is designed for use in scikit-learn pipelines. It performs the following steps:\n",
    "    \n",
    "    1. Checks that required columns (\"timestamp\", \"motor_pump\", \"resource\", \"value\", \"running\") are present.\n",
    "    2. Pivots the DataFrame from long to wide format using \"resource\" as columns and \"value\" as values.\n",
    "    3. Merges the \"running\" column back into the wide DataFrame.\n",
    "    4. Sets \"timestamp\" as the index.\n",
    "    5. Resamples the data for each \"motor_pump\" at a fixed interval (`resample_seconds`), filling missing values with forward fill.\n",
    "    6. Rounds the \"running\" column to integer and ensures proper sorting and deduplication.\n",
    "\n",
    "    Args:\n",
    "        resample_seconds (int, optional): The interval in seconds for resampling the time-series data. Defaults to 60.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Returns self. Required for compatibility with scikit-learn pipelines.\n",
    "        transform(X):\n",
    "            Returns a cleaned, pivoted, and resampled DataFrame.\n",
    "            \n",
    "    Raises:\n",
    "        ValueError: If any of the required columns are missing from the input DataFrame.\"\"\"\n",
    "    def __init__(self, resample_seconds: int = 60):\n",
    "        self.resample_seconds = resample_seconds\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        df = X.copy()\n",
    "\n",
    "        required_cols = {\"timestamp\", \"motor_pump\", \"resource\", \"value\", \"running\"}\n",
    "        missing = required_cols - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"PivotDataframe: missing columns: {missing}\")\n",
    "\n",
    "\n",
    "        df_wide = (\n",
    "        df.pivot_table(\n",
    "            index=[\"timestamp\", \"motor_pump\"],\n",
    "            columns=\"resource\",\n",
    "            values=\"value\",\n",
    "            aggfunc=\"mean\"\n",
    "        )\n",
    "        .reset_index()\n",
    "        )\n",
    "\n",
    "        df_running = df[[\"timestamp\", \"motor_pump\", \"running\"]]\n",
    "        df_wide = df_wide.merge(df_running, on=[\"timestamp\", \"motor_pump\"], how=\"left\")\n",
    "        df_wide = df_wide.set_index(\"timestamp\")\n",
    "\n",
    "        resampled = []\n",
    "        for pump_id, group in df_wide.groupby(\"motor_pump\"):\n",
    "            g = (\n",
    "                group\n",
    "                .resample(f\"{self.resample_seconds}s\")\n",
    "                .mean(numeric_only=True)\n",
    "                .ffill()\n",
    "            )\n",
    "            g[\"running\"] = g[\"running\"].round().astype(int)\n",
    "            g[\"motor_pump\"] = pump_id\n",
    "            resampled.append(g)\n",
    "\n",
    "        df_wide = pd.concat(resampled).reset_index()\n",
    "        df_wide = df_wide.sort_values([\"motor_pump\", \"timestamp\"]).reset_index(drop=True)\n",
    "        return df_wide.drop_duplicates().ffill()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39431683",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveZeroColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer that removes columns containing only zeros.\n",
    "\n",
    "    This transformer is designed to be used in scikit-learn pipelines. It identifies\n",
    "    columns where all values are zero during fitting and removes them during transformation.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Identifies columns that contain only zeros and stores the ones to keep.\n",
    "        transform(X):\n",
    "            Returns a DataFrame with zero-only columns removed.\"\"\"\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        zero_columns = (X == 0).all()\n",
    "        self.columns_to_keep_ = zero_columns[~zero_columns].index\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        return X[self.columns_to_keep_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2032f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"adjust_timestamp\", AdjustTimestampColumn()),\n",
    "    (\"remove_duplicates_and_nan\", RemoveDuplicatesAndNaN()),\n",
    "    (\"treat_high_values\", TreatHighValues()),\n",
    "    (\"fix_battery_and_alternator_values\", FixBatteryAndAlternatorValues()),\n",
    "    (\"pivot_dataframe\", PivotDataframe(resample_seconds=15)),\n",
    "    (\"remove_zero_columns\", RemoveZeroColumns())\n",
    "])\n",
    "\n",
    "df_raw = load_and_concat_data_from_csv(df_itu_415_csv_locations)\n",
    "df_processed = pipeline.fit_transform(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
