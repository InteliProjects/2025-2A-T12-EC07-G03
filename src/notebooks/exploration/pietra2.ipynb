{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc36656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8964925",
   "metadata": {},
   "source": [
    "## ITU - 415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6186be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = [\n",
    "    \"../data/full_history_ITU-415_2025-06-01_a_2025-06-17.csv\",\n",
    "    \"../data/full_history_ITU-415_2025-06-17_a_2025-06-29.csv\",\n",
    "    \"../data/full_history_ITU-415_2025-06-29_a_2025-06-31.csv\",\n",
    "    \"../data/full_history_ITU-415_2025-07-01_a_2025-07-17 (1).csv\"\n",
    "]\n",
    "\n",
    "total = 0\n",
    "for f in arquivos:\n",
    "    nlinhas = pd.read_csv(f).shape[0]\n",
    "    print(f\"{f} → {nlinhas} linhas\")\n",
    "    total += nlinhas\n",
    "\n",
    "print(f\"\\nTotal de linhas somadas: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818ca3d",
   "metadata": {},
   "source": [
    "#### Concatenação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca036c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415 = pd.concat([pd.read_csv(f) for f in arquivos], ignore_index=True)\n",
    "\n",
    "print(df_415.shape)\n",
    "df_415.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3514db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132b70",
   "metadata": {},
   "source": [
    "#### Mudar de object para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415[\"timestamp\"] = pd.to_datetime(df_415[\"timestamp\"], utc=True, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linhas x colunas:\", df_415.shape)\n",
    "print(df_415.head(10))\n",
    "print(\"\\nRecursos (sensores) disponíveis:\\n\", df_415[\"resource\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04578a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sensores únicos:\", df_415['resource'].nunique())\n",
    "print(df_415['resource'].unique())  # lista todos, na ordem em que aparecem no DataFrame\n",
    "print(\"Período:\", df_415['timestamp'].min(), \"→\", df_415['timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa793c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop = df_415[df_415[\"resource\"] == \"Stop\"].copy()\n",
    "print(\"Valores únicos do STOP:\", df_stop[\"value\"].unique())\n",
    "\n",
    "print(\"\\nFrequência de cada valor STOP:\")\n",
    "print(df_stop[\"value\"].value_counts(dropna=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415[\"timestamp_diff\"] = df_415[\"timestamp\"].diff().dt.total_seconds()\n",
    "\n",
    "print(df_415[\"timestamp_diff\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df_415[\"timestamp_diff\"].dropna(), bins=200, range=(0,5))\n",
    "plt.xlabel(\"Intervalo entre leituras (s)\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.title(\"Distribuição dos intervalos (zoom até 5s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que calcula estatísticas do delta por sensor\n",
    "def sensor_freq_stats(df):\n",
    "    out = {}\n",
    "    for res, group in df.groupby(\"resource\"):\n",
    "        diffs = group[\"timestamp\"].sort_values().diff().dt.total_seconds().dropna()\n",
    "        if len(diffs) > 0:\n",
    "            out[res] = {\n",
    "                \"n_registros\": len(group),\n",
    "                \"mediana_s\": diffs.median(),\n",
    "                \"media_s\": diffs.mean(),\n",
    "                \"p25_s\": diffs.quantile(0.25),\n",
    "                \"p75_s\": diffs.quantile(0.75),\n",
    "                \"max_s\": diffs.max()\n",
    "            }\n",
    "    return pd.DataFrame(out).T.sort_values(\"mediana_s\")\n",
    "\n",
    "freq_table = sensor_freq_stats(df_415)\n",
    "\n",
    "# visualizar top e bottom\n",
    "print(freq_table.head(10))   # sensores mais rápidos\n",
    "print(freq_table.tail(10))   # sensores mais lentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_cols = [str(c) for c in df_415[\"resource\"].unique() if isinstance(c, str) and \"FlexAnalogue\" in str(c)]\n",
    "print(\"FlexAnalogues encontrados:\", flex_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92200173",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = df_415.loc[df_415[\"resource\"] == \"STOP\", [\"timestamp\", \"value\"]].copy()\n",
    "stop = stop.sort_values(\"timestamp\").drop_duplicates(subset=\"timestamp\", keep=\"last\")\n",
    "stop[\"STOP\"] = stop[\"value\"].round().astype(int)\n",
    "\n",
    "status_15s = (\n",
    "    stop.set_index(\"timestamp\")[[\"STOP\"]]\n",
    "        .resample(\"15S\").last()\n",
    "        .ffill()\n",
    ")\n",
    "status_15s[\"status\"] = status_15s[\"STOP\"].map({0: \"ON\", 1: \"OFF\"}).astype(\"category\")\n",
    "\n",
    "print(status_15s[\"status\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT = 2.1e9\n",
    "rec = df_415.loc[df_415[\"resource\"] == \"Recalque\", [\"timestamp\", \"value\"]].copy()\n",
    "rec = rec.sort_values(\"timestamp\").drop_duplicates(subset=\"timestamp\", keep=\"last\")\n",
    "rec.loc[rec[\"value\"] >= SENT, \"value\"] = np.nan\n",
    "\n",
    "rec_15s = (\n",
    "    rec.set_index(\"timestamp\")[\"value\"]\n",
    "       .resample(\"15S\").mean()\n",
    ")\n",
    "\n",
    "print(\"Recalque 15s - % nulos:\", rec_15s.isna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18617c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def series_15s(df_sensor):\n",
    "    \"\"\"Limpa sentinela e reamostra em 15s (média).\"\"\"\n",
    "    s = df_sensor.sort_values(\"timestamp\").drop_duplicates(subset=\"timestamp\", keep=\"last\").copy()\n",
    "    s.loc[s[\"value\"] >= SENT, \"value\"] = np.nan\n",
    "    return s.set_index(\"timestamp\")[\"value\"].resample(\"15S\").mean()\n",
    "\n",
    "def diffs_stats(df_sensor):\n",
    "    \"\"\"Estatísticas de intervalo entre amostras (em segundos).\"\"\"\n",
    "    g = df_sensor.sort_values(\"timestamp\")[\"timestamp\"].diff().dt.total_seconds().dropna()\n",
    "    if len(g) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    return np.median(g), np.mean(g), np.max(g)\n",
    "\n",
    "def safe_corr(a, b):\n",
    "    \"\"\"Correlação de Pearson entre duas séries alinhadas (dropna).\"\"\"\n",
    "    tmp = pd.concat([a, b], axis=1, keys=[\"x\",\"y\"]).dropna()\n",
    "    if len(tmp) < 10:\n",
    "        return np.nan\n",
    "    try:\n",
    "        r, _ = pearsonr(tmp[\"x\"], tmp[\"y\"])\n",
    "        return r\n",
    "    except Exception:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_cols = ['FlexAnalogue1_1', 'FlexAnalogue1_2', 'FlexAnalogue2_1', 'FlexAnalogue2_2',\n",
    "             'FlexAnalogue3_1', 'FlexAnalogue3_2', 'FlexAnalogue4_1', 'FlexAnalogue4_2',\n",
    "             'FlexAnalogue6_1', 'FlexAnalogue6_2', 'FlexAnalogue7_1', 'FlexAnalogue7_2',\n",
    "             'FlexAnalogue8_1', 'FlexAnalogue8_2', 'FlexAnalogue9_1', 'FlexAnalogue9_2',\n",
    "             'FlexAnalogue10_1', 'FlexAnalogue10_2', 'FlexAnalogue11_1', 'FlexAnalogue11_2',\n",
    "             'FlexAnalogue12_1', 'FlexAnalogue12_2']\n",
    "\n",
    "rows = []\n",
    "for col in flex_cols:\n",
    "    sub = df_415.loc[df_415[\"resource\"] == col, [\"timestamp\",\"value\"]].copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "\n",
    "    # stats de intervalo (frequência) na série crua\n",
    "    med_s, mean_s, max_s = diffs_stats(sub)\n",
    "\n",
    "    # série 15s\n",
    "    s15 = series_15s(sub)\n",
    "\n",
    "    # cobertura em ON\n",
    "    joined = status_15s.join(s15.to_frame(name=col), how=\"left\")\n",
    "    on = joined[joined[\"status\"]==\"ON\"][col]\n",
    "    coverage_on = 1 - on.isna().mean()\n",
    "\n",
    "    # estatísticas de valor em ON\n",
    "    vmin = np.nanmin(on.values) if on.notna().any() else np.nan\n",
    "    vmed = np.nanmedian(on.values) if on.notna().any() else np.nan\n",
    "    vp95 = np.nanpercentile(on.values, 95) if on.notna().any() else np.nan\n",
    "\n",
    "    # correlação com Recalque (em ON)\n",
    "    corr_rec = safe_corr(on, rec_15s.loc[on.index])\n",
    "\n",
    "    rows.append({\n",
    "        \"sensor\": col,\n",
    "        \"freq_mediana_s\": med_s,\n",
    "        \"freq_media_s\": mean_s,\n",
    "        \"freq_max_s\": max_s,\n",
    "        \"coverage_ON\": coverage_on,\n",
    "        \"min_ON\": vmin,\n",
    "        \"median_ON\": vmed,\n",
    "        \"p95_ON\": vp95,\n",
    "        \"corr_with_Recalque_ON\": corr_rec,\n",
    "    })\n",
    "\n",
    "flex_report = pd.DataFrame(rows).sort_values(\n",
    "    [\"coverage_ON\", \"freq_mediana_s\"], ascending=[False, True]\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "flex_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in flex_cols:\n",
    "    vals = df_415.loc[df_415[\"resource\"]==col, \"value\"]\n",
    "    print(col, \"unique:\", vals.nunique(), \n",
    "          \"min:\", vals.min(), \"max:\", vals.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# séries já tratadas (limpando sentinela)\n",
    "rec = df_415.loc[df_415[\"resource\"]==\"Recalque\", [\"timestamp\",\"value\"]].copy()\n",
    "rec.loc[rec[\"value\"] >= 2.1e9, \"value\"] = np.nan\n",
    "rec = rec.set_index(\"timestamp\").sort_index().resample(\"1min\").mean()\n",
    "\n",
    "f41 = df_415.loc[df_415[\"resource\"]==\"FlexAnalogue4_1\", [\"timestamp\",\"value\"]].copy()\n",
    "f41.loc[f41[\"value\"] >= 2.1e9, \"value\"] = np.nan\n",
    "f41 = f41.set_index(\"timestamp\").sort_index().resample(\"1min\").mean()\n",
    "\n",
    "f42 = df_415.loc[df_415[\"resource\"]==\"FlexAnalogue4_2\", [\"timestamp\",\"value\"]].copy()\n",
    "f42.loc[f42[\"value\"] >= 2.1e9, \"value\"] = np.nan\n",
    "f42 = f42.set_index(\"timestamp\").sort_index().resample(\"1min\").mean()\n",
    "\n",
    "# correlação\n",
    "print(\"Corr Recalque vs Flex4_1:\", rec.corr(f41))\n",
    "print(\"Corr Recalque vs Flex4_2:\", rec.corr(f42))\n",
    "\n",
    "# gráfico comparativo (1 semana ou 1 dia, pra não ficar pesado)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(rec.index[:500], rec.values[:500], label=\"Recalque\")\n",
    "plt.plot(f41.index[:500], f41.values[:500], label=\"Flex4_1\")\n",
    "plt.plot(f42.index[:500], f42.values[:500], label=\"Flex4_2\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparativo Recalque vs FlexAnalogue4_1 e 4_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fb6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(rec), rec.head())\n",
    "print(type(f41), f41.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SENT = 2.1e9\n",
    "\n",
    "def one_min_series(df, resource):\n",
    "    s = df.loc[df[\"resource\"]==resource, [\"timestamp\",\"value\"]].copy()\n",
    "    if s.empty:\n",
    "        return None\n",
    "    s[\"timestamp\"] = pd.to_datetime(s[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    s = s.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\").drop_duplicates(subset=\"timestamp\", keep=\"last\")\n",
    "    s.loc[s[\"value\"] >= SENT, \"value\"] = np.nan\n",
    "    s = s.set_index(\"timestamp\")[\"value\"].resample(\"1min\").mean()  # <- Series!\n",
    "    s.name = resource\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = one_min_series(df_415, \"Recalque\")\n",
    "f41 = one_min_series(df_415, \"FlexAnalogue4_1\")\n",
    "f42 = one_min_series(df_415, \"FlexAnalogue4_2\")\n",
    "\n",
    "# Empilha e alinha por índice\n",
    "pair_41 = pd.concat([rec, f41], axis=1).dropna()\n",
    "pair_42 = pd.concat([rec, f42], axis=1).dropna()\n",
    "\n",
    "# Correlações (escalares)\n",
    "corr_41 = pair_41.corr().loc[\"Recalque\",\"FlexAnalogue4_1\"] if not pair_41.empty else np.nan\n",
    "corr_42 = pair_42.corr().loc[\"Recalque\",\"FlexAnalogue4_2\"] if not pair_42.empty else np.nan\n",
    "\n",
    "print(\"Corr(Recalque, Flex4_1) =\", corr_41)\n",
    "print(\"Corr(Recalque, Flex4_2) =\", corr_42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8723f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# escolha uma janela curta para visualizar (ex.: as primeiras 500 amostras válidas)\n",
    "w = 500\n",
    "viz = pair_41.iloc[:w] if len(pair_41) >= w else pair_41\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(viz.index, viz[\"Recalque\"], label=\"Recalque\")\n",
    "plt.plot(viz.index, viz[\"FlexAnalogue4_1\"], label=\"FlexAnalogue4_1\")\n",
    "plt.title(\"Recalque vs FlexAnalogue4_1 (1min)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "viz = pair_42.iloc[:w] if len(pair_42) >= w else pair_42\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(viz.index, viz[\"Recalque\"], label=\"Recalque\")\n",
    "plt.plot(viz.index, viz[\"FlexAnalogue4_2\"], label=\"FlexAnalogue4_2\")\n",
    "plt.title(\"Recalque vs FlexAnalogue4_2 (1min)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recalque válidos:\", rec.notna().sum())\n",
    "print(\"Flex4_1 válidos:\", f41.notna().sum())\n",
    "print(\"Flex4_2 válidos:\", f42.notna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59075aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"join Recalque + Flex4_1:\", len(pair_41))\n",
    "print(\"join Recalque + Flex4_2:\", len(pair_42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9717e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_raw = df_415[df_415[\"resource\"]==\"Recalque\"][\"value\"]\n",
    "print(\"N registros:\", len(rec_raw))\n",
    "print(\"Valores únicos:\", rec_raw.nunique())\n",
    "print(\"Min:\", rec_raw.min(), \"Max:\", rec_raw.max())\n",
    "print(rec_raw.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SENT_VALUES = [2147483647, 2147483645]  # possíveis sentinelas\n",
    "\n",
    "def diagnostico_resources(df):\n",
    "    rows = []\n",
    "    for res, g in df.groupby(\"resource\"):\n",
    "        vals = g[\"value\"].values\n",
    "\n",
    "        n = len(vals)\n",
    "        unicos = len(np.unique(vals))\n",
    "        vmin, vmax = np.nanmin(vals), np.nanmax(vals)\n",
    "\n",
    "        # contagem de sentinelas\n",
    "        mask_sent = np.isin(vals, SENT_VALUES)\n",
    "        perc_sent = mask_sent.mean() if n > 0 else np.nan\n",
    "        perc_valid = 1 - perc_sent if perc_sent is not np.nan else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"resource\": res,\n",
    "            \"n_registros\": n,\n",
    "            \"n_valores_unicos\": unicos,\n",
    "            \"min\": vmin,\n",
    "            \"max\": vmax,\n",
    "            \"%_sentinela\": round(perc_sent*100,2),\n",
    "            \"%_validos\": round(perc_valid*100,2)\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"%_validos\", ascending=False)\n",
    "\n",
    "diag = diagnostico_resources(df_415)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "print(diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(df_415[\"resource\"].dropna().unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "vib = df_415[df_415[\"resource\"]==\"Vibracao\"][\"value\"]\n",
    "\n",
    "print(\"N registros:\", len(vib))\n",
    "print(\"Valores únicos:\", vib.nunique())\n",
    "print(\"Min:\", vib.min(), \"Max:\", vib.max())\n",
    "\n",
    "print(\"\\nAmostra:\")\n",
    "print(vib.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a44211",
   "metadata": {},
   "outputs": [],
   "source": [
    "f41 = df_415[df_415[\"resource\"]==\"FlexAnalogue4_1\"][\"value\"].replace([2147483647,2147483645], np.nan)\n",
    "f42 = df_415[df_415[\"resource\"]==\"FlexAnalogue4_2\"][\"value\"].replace([2147483647,2147483645], np.nan)\n",
    "\n",
    "print(\"Flex4_1 min:\", f41.min(), \"max:\", f41.max(), \"unique:\", f41.nunique())\n",
    "print(\"Flex4_2 min:\", f42.min(), \"max:\", f42.max(), \"unique:\", f42.nunique())\n",
    "print(\"Correlação bruta entre Flex4_1 e Flex4_2:\", f41.corr(f42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98413ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def to_series(df, resource, freq=\"15S\"):\n",
    "    s = df[df[\"resource\"]==resource][[\"timestamp\",\"value\"]].copy()\n",
    "    s[\"timestamp\"] = pd.to_datetime(s[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    s = s.dropna().drop_duplicates(\"timestamp\")\n",
    "    s.loc[s[\"value\"].isin([2147483647,2147483645]), \"value\"] = np.nan\n",
    "    return s.set_index(\"timestamp\")[\"value\"].resample(freq).mean()\n",
    "\n",
    "f41_15s = to_series(df_415, \"FlexAnalogue4_1\")\n",
    "f42_15s = to_series(df_415, \"FlexAnalogue4_2\")\n",
    "\n",
    "pair = pd.concat([f41_15s, f42_15s], axis=1)\n",
    "print(pair.corr())\n",
    "\n",
    "print(\"\\nResumo estatístico:\")\n",
    "print(pair.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a1077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_415_long = df_415.copy()\n",
    "df_415_long[\"timestamp\"] = pd.to_datetime(df_415_long[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# renomeia apenas o canal identificado como sucção\n",
    "df_415_long[\"resource\"] = df_415_long[\"resource\"].replace({\"FlexAnalogue4_1\": \"Succao\"})\n",
    "\n",
    "print(\"Existe 'Succao' agora?\", \"Succao\" in df_415_long[\"resource\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trabalhe numa CÓPIA para não mexer no original:\n",
    "df = df_415_long.copy()\n",
    "\n",
    "# --- Diagnóstico antes da limpeza ---\n",
    "SENT = {2147483647.0, 2147483645.0}\n",
    "\n",
    "total_counts = df.groupby(\"resource\")[\"value\"].size()\n",
    "sent_counts  = df[\"value\"].isin(SENT).groupby(df[\"resource\"]).sum()\n",
    "report = pd.DataFrame({\n",
    "    \"n_registros\": total_counts,\n",
    "    \"n_sentinela\": sent_counts.fillna(0).astype(int)\n",
    "})\n",
    "report[\"pct_sentinela\"] = (report[\"n_sentinela\"] / report[\"n_registros\"] * 100).round(2)\n",
    "print(\">>> Sentinelas por resource (ANTES):\")\n",
    "print(report.sort_values(\"pct_sentinela\", ascending=False).head(20))\n",
    "\n",
    "# --- LIMPEZA: transformar sentinela em NaN para todos, EXCETO STOP (0/1 é dado válido) ---\n",
    "mask = df[\"value\"].isin(SENT) & (df[\"resource\"].str.lower() != \"stop\")\n",
    "df.loc[mask, \"value\"] = np.nan\n",
    "\n",
    "# --- Checagens pós-limpeza ---\n",
    "print(\"\\n>>> STOP (deve continuar 0/1):\",\n",
    "      df.loc[df[\"resource\"].str.lower()==\"stop\", \"value\"].dropna().unique())\n",
    "\n",
    "n_rec_reais = df.loc[df[\"resource\"]==\"Recalque\", \"value\"].dropna().size\n",
    "print(\"Recalque - leituras válidas após limpeza (esperado 0):\", n_rec_reais)\n",
    "\n",
    "succao_nan_pct = df.loc[df[\"resource\"]==\"Succao\", \"value\"].isna().mean()*100\n",
    "print(f\"Succao - % NaN após limpeza: {succao_nan_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_keep = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde48ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_415 = {\n",
    "    \"Succao\",       # renomeado do FlexAnalogue4_1\n",
    "    \"Eng_RPM\",\n",
    "    \"Oil_P\",\n",
    "    \"Cool_T\",\n",
    "    \"Oil_L\",\n",
    "    \"Fuel_Con\",\n",
    "    \"Fuel_L\",\n",
    "    \"Stop\",\n",
    "    \"Auto\", \"Man\",\n",
    "    \"Bat_V\", \"Char_V\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partimos do df (a CÓPIA limpa do 415)\n",
    "res_col = df[\"resource\"]  # não precisa converter tipo\n",
    "\n",
    "keep_415 = {\n",
    "    \"Succao\", \"Eng_RPM\", \"Oil_P\", \"Cool_T\", \"Oil_L\",\n",
    "    \"Fuel_Con\", \"Fuel_L\", \"Stop\", \"Auto\", \"Man\", \"Bat_V\", \"Char_V\",\n",
    "}\n",
    "\n",
    "# mantém somente os resources de interesse\n",
    "df_415_keep = df[res_col.isin(keep_415)].copy()\n",
    "\n",
    "print(\"Resources mantidos no 415:\\n\", sorted(df_415_keep[\"resource\"].dropna().unique()))\n",
    "print(\"Tamanho final (long):\", df_415_keep.shape)\n",
    "\n",
    "# checagem: % de valores válidos por resource (após limpeza)\n",
    "valid_rate = (\n",
    "    df_415_keep.assign(valid = df_415_keep[\"value\"].notna())\n",
    "               .groupby(\"resource\")[\"valid\"].mean()\n",
    "               .sort_values(ascending=False)\n",
    "               .round(3)\n",
    ")\n",
    "print(\"\\n% de valores válidos por resource:\\n\", valid_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = (\n",
    "    df_415_keep\n",
    "      .groupby([\"timestamp\",\"resource\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"cnt\")\n",
    ")\n",
    "print(\"Pares (timestamp, resource) com cnt>1:\",\n",
    "      (dups[\"cnt\"]>1).sum())\n",
    "dups[dups[\"cnt\"]>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbcdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_keep = (\n",
    "    df_415_keep\n",
    "      .sort_values([\"timestamp\", \"resource\"])\n",
    "      .drop_duplicates(subset=[\"timestamp\", \"resource\"], keep=\"last\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = (\n",
    "    df_415_keep\n",
    "      .groupby([\"timestamp\",\"resource\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"cnt\")\n",
    ")\n",
    "print(\"Pares (timestamp, resource) com cnt>1:\",\n",
    "      (dups[\"cnt\"]>1).sum())\n",
    "dups[dups[\"cnt\"]>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_wide = (\n",
    "    df_415_keep\n",
    "      .pivot_table(index=\"timestamp\", columns=\"resource\", values=\"value\", aggfunc=\"mean\")\n",
    "      .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88adff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_wide.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78604f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da86849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) copiar o long filtrado\n",
    "df_fix = df_415_keep.copy()\n",
    "\n",
    "# 2) marcar quais linhas têm valor válido (não-NaN)\n",
    "df_fix[\"is_valid\"] = df_fix[\"value\"].notna()\n",
    "\n",
    "# 3) ordenar de modo que valores válidos fiquem por último dentro do mesmo (timestamp, resource)\n",
    "df_fix = (\n",
    "    df_fix\n",
    "      .sort_values([\"timestamp\", \"resource\", \"is_valid\"])   # False (NaN) vem antes, True (válido) depois\n",
    "      .drop_duplicates(subset=[\"timestamp\", \"resource\"], keep=\"last\")  # mantém o válido se existir\n",
    "      .drop(columns=\"is_valid\")\n",
    ")\n",
    "\n",
    "# 4) pivotar de novo (long -> wide)\n",
    "df_415_wide = (\n",
    "    df_fix\n",
    "      .pivot_table(index=\"timestamp\", columns=\"resource\", values=\"value\", aggfunc=\"mean\")\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "print(\"Shape wide (refeito):\", df_415_wide.shape)\n",
    "print(\"Exemplo:\", df_415_wide.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SENT = {2147483647.0, 2147483645.0}\n",
    "\n",
    "# 1) partir do long filtrado que você já tem\n",
    "df_fix = df_415_keep.copy()\n",
    "\n",
    "# 1a) garantir limpeza de sentinelas AQUI (independe do que foi feito antes)\n",
    "mask_sent = df_fix[\"value\"].isin(SENT) & (df_fix[\"resource\"].str.lower() != \"stop\")\n",
    "df_fix.loc[mask_sent, \"value\"] = np.nan\n",
    "\n",
    "# 2) deduplicar mantendo o válido (não-NaN)\n",
    "df_fix[\"is_valid\"] = df_fix[\"value\"].notna()\n",
    "df_fix = (\n",
    "    df_fix\n",
    "      .sort_values([\"timestamp\", \"resource\", \"is_valid\"])  # NaN primeiro, válidos por último\n",
    "      .drop_duplicates(subset=[\"timestamp\", \"resource\"], keep=\"last\")\n",
    "      .drop(columns=\"is_valid\")\n",
    ")\n",
    "\n",
    "# 3) pivot long -> wide\n",
    "df_415_wide = (\n",
    "    df_fix\n",
    "      .pivot_table(index=\"timestamp\", columns=\"resource\", values=\"value\", aggfunc=\"mean\")\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "print(\"Shape wide (limpo):\", df_415_wide.shape)\n",
    "print(df_415_wide.head(5))\n",
    "\n",
    "# 4) checagem: nenhum sentinela deve restar\n",
    "leftovers = {\n",
    "    col: int((df_415_wide[col].isin(SENT)).sum())\n",
    "    for col in df_415_wide.columns if col != \"Stop\"\n",
    "}\n",
    "print(\"Sentinelas remanescentes por coluna (deve ser 0):\", leftovers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm_vals = df_415_wide[\"Eng_RPM\"].dropna().unique()\n",
    "print(\"Nº de valores únicos de Eng_RPM:\", len(rpm_vals))\n",
    "print(\"Exemplos:\", rpm_vals[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegar só as linhas em que RPM é exatamente 0\n",
    "rpm_zeros = df_415_wide[df_415_wide[\"Eng_RPM\"] == 0]\n",
    "\n",
    "print(\"Qtd de registros com RPM = 0:\", len(rpm_zeros))\n",
    "print(rpm_zeros[[\"Eng_RPM\", \"Stop\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegar só as linhas em que RPM é exatamente 0\n",
    "rpm_sentinela = df_415_wide[df_415_wide[\"Eng_RPM\"] == 2147483643.0]\n",
    "\n",
    "print(\"Qtd de registros com RPM = 2.147484e+09:\", len(rpm_sentinela))\n",
    "print(rpm_sentinela[[\"Eng_RPM\", \"Stop\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rpm_valid = df_415_wide[\"Eng_RPM\"].dropna()\n",
    "rpm_valid = rpm_valid[rpm_valid < 1e6]  # tira sentinelas\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "rpm_valid.hist(bins=50)\n",
    "plt.title(\"Distribuição de Eng_RPM (sem sentinelas)\")\n",
    "plt.xlabel(\"RPM\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SENT = [2147483647.0, 2147483645.0]\n",
    "TOL = 1  # tolerância numérica\n",
    "\n",
    "mask_rpm_sentinel = df_415_wide[\"Eng_RPM\"].apply(\n",
    "    lambda x: pd.notna(x) and any(abs(x - s) <= TOL for s in SENT)\n",
    ")\n",
    "\n",
    "print(\"Qtd de registros Eng_RPM = sentinela:\", mask_rpm_sentinel.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listar todos os valores únicos de RPM (ordenados)\n",
    "rpm_vals = sorted(df_415_wide[\"Eng_RPM\"].dropna().unique())\n",
    "print(\"Nº de valores únicos:\", len(rpm_vals))\n",
    "print(\"Todos os valores:\")\n",
    "for v in rpm_vals:\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943534a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_vals = df_415_wide[\"Stop\"].unique()\n",
    "print(\"Valores únicos em Stop:\", stop_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ed6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_415_wide[\"Stop\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d00d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_415_wide.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopped = df_415_wide[df_415_wide[\"Stop\"] == 1.0]\n",
    "print(\"Qtd de registros com Stop=1:\", len(stopped))\n",
    "print(stopped.describe().T[[\"min\",\"mean\",\"max\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "working = df_415_wide[df_415_wide[\"Stop\"] == 0.0]\n",
    "print(\"Qtd de registros com Stop=0:\", len(working))\n",
    "print(working.describe().T[[\"min\",\"mean\",\"max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria uma nova coluna Stop_ffill aplicando forward fill\n",
    "df_415_wide[\"Stop_ffill\"] = df_415_wide[\"Stop\"].fillna(method=\"ffill\")\n",
    "\n",
    "# checa quantos registros ficaram em cada status\n",
    "print(df_415_wide[\"Stop_ffill\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8762c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_415_wide[\"Stop_ffill\"] = (\n",
    "    df_415_wide[\"Stop\"]\n",
    "    .fillna(method=\"ffill\")\n",
    "    .fillna(method=\"bfill\")  # preenche o que ficou vazio no começo\n",
    ")\n",
    "\n",
    "print(\"Total linhas:\", len(df_415_wide))\n",
    "print(df_415_wide[\"Stop_ffill\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d705b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listar todos os valores únicos de RPM (ordenados)\n",
    "rpm_vals = sorted(df_415_wide[\"Eng_RPM\"].dropna().unique())\n",
    "print(\"Nº de valores únicos:\", len(rpm_vals))\n",
    "print(\"Todos os valores:\")\n",
    "for v in rpm_vals:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# garantir que Stop_ffill está 100% preenchido\n",
    "df_415_wide[\"Stop_ffill\"] = (\n",
    "    df_415_wide[\"Stop\"]\n",
    "    .fillna(method=\"ffill\")\n",
    "    .fillna(method=\"bfill\")\n",
    ")\n",
    "\n",
    "# selecionar um intervalo pequeno (ex: primeiras 2h de dados)\n",
    "subset = df_415_wide.iloc[:5000]  # ~primeiras 500 linhas\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "# eixo Y1 -> RPM\n",
    "ax1.plot(subset.index, subset[\"Eng_RPM\"], color=\"tab:blue\", label=\"Eng_RPM\")\n",
    "ax1.set_ylabel(\"RPM\", color=\"tab:blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "# eixo Y2 -> Stop_ffill\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(subset.index, subset[\"Stop_ffill\"], color=\"tab:red\", linestyle=\"--\", label=\"Stop_ffill\")\n",
    "ax2.set_ylabel(\"Stop_ffill (0=ligado, 1=desligado)\", color=\"tab:red\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "# título e legenda\n",
    "plt.title(\"Eng_RPM vs Stop_ffill (primeiro intervalo)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
